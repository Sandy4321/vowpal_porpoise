{"name":"vowpal_porpoise","tagline":"lightweight python wrapper for vowpal wabbit","body":"# vowpal_porpoise\r\n\r\nLightweight python wrapper for [vowpal_wabbit](https://github.com/JohnLangford/vowpal_wabbit/).\r\n\r\nWhy: Scalable, blazingly fast machine learning.\r\n\r\n## Install\r\n\r\n1. Install [vowpal_wabbit](https://github.com/JohnLangford/vowpal_wabbit/). Clone and run ``make``\r\n2. Install [cython](http://www.cython.org/). ```pip install cython```\r\n3. Clone [vowpal_porpoise](https://github.com/josephreisinger/vowpal_porpoise)\r\n4. Run: ```python setup.py install``` to install.\r\n\r\nNow can you do: ```import vowpal_porpoise``` from python.\r\n\r\n## Examples\r\n\r\n### Standard Interface\r\n\r\nLinear regression with l1 penalty:\r\n```python\r\nfrom vowpal_porpoise import VW\r\n\r\n# Initialize the model\r\nvw = VW(moniker='test',    # a name for the model\r\n        passes=10,         # vw arg: passes\r\n        loss='quadratic',  # vw arg: loss\r\n        learning_rate=10,  # vw arg: learning_rate\r\n        l1=0.01)           # vw arg: l1\r\n\r\n# Inside the with training() block a vw process will be \r\n# open to communication\r\nwith vw.training():\r\n    for instance in ['1 |big red square',\\\r\n                      '0 |small blue circle']:\r\n        vw.push_instance(instance)\r\n\r\n    # here stdin will close\r\n# here the vw process will have finished\r\n\r\n# Inside the with predicting() block we can stream instances and \r\n# acquire their labels\r\nwith vw.predicting():\r\n    for instance in ['1 |large burnt sienna rhombus',\\\r\n                      '0 |little teal oval']:\r\n        vw.push_instance(instance)\r\n\r\n# Read the predictions like this:\r\npredictions = list(vw.read_predictions_())\r\n```\r\n\r\nL-BFGS with a rank-5 approximation:\r\n```python\r\nfrom vowpal_porpoise import VW\r\n\r\n# Initialize the model\r\nvw = VW(moniker='test_lda',  # a name for the model\r\n        passes=10,           # vw arg: passes\r\n        lbfgs=True,          # turn on lbfgs\r\n        mem=5)               # lbfgs rank\r\n```\r\n\r\nLatent Dirichlet Allocation with 100 topics:\r\n```python\r\nfrom vowpal_porpoise import VW\r\n\r\n# Initialize the model\r\nvw = VW(moniker='test_lda',  # a name for the model\r\n        passes=10,           # vw arg: passes\r\n        lda=100,             # turn on lda\r\n        minibatch=100)       # set the minibatch size\r\n```\r\n\r\n\r\n\r\n### Library Interace (TESTING)\r\n\r\nVia the ```VW``` interface:\r\n```python\r\nwith vw.predicting_library():\r\n    for instance in ['1 |large burnt sienna rhombus', \\\r\n                      '1 |little teal oval']:\r\n        prediction = vw.push_instance(instance)\r\n```\r\nNow the predictions are returned directly to the parent process, rather than having to read from disk.\r\nSee ```examples/example1.py``` for more details.\r\n\r\nAlternatively you can use the raw library interface:\r\n```python\r\nimport vw_c\r\nvw = vw_c.VW(\"--loss=quadratic --l1=0.01 -f model\")\r\nvw.learn(\"1 |this is a positive example\")\r\nvw.learn(\"0 |this is a negative example\")\r\nvw.finish()\r\n```\r\nCurrently does not support passes due to some limitations in the underlying vw C code.\r\n\r\n### Need more examples?\r\n\r\n* [example1.py](https://github.com/josephreisinger/vowpal_porpoise/blob/master/examples/example1.py): SimpleModel class wrapper around VP (both standard and library flavors)\r\n* [example_library.py](https://github.com/josephreisinger/vowpal_porpoise/blob/master/examples/example_library.py): Demonstrates the low-level vw library wrapper, classifying lines of **alice in wonderland** vs **through the looking glass**.\r\n\r\n## Why\r\n\r\nvowpal\\_wabbit is **insanely**\r\nfast and scalable. vowpal_porpoise is slower, but **only** during the\r\ninitial training pass. Once the data has been properly cached it will idle while vowpal\\_wabbit does all the heavy lifting.\r\nFurthermore, vowpal\\_porpoise was designed to be lightweight and not to get in the way\r\nof vowpal\\_wabbit's scalability, e.g. it allows distributed learning via\r\n```--nodes``` and does not require data to be batched in memory. In our\r\nresearch work we use vowpal\\_porpoise on an 80-node cluster running over multiple\r\nterabytes of data.\r\n\r\nThe main benefit of vowpal\\_porpoise is allowing **rapid prototyping** of new\r\nmodels and feature extractors. We found that we had been doing this in an\r\nad-hoc way using python scripts to shuffle around massive gzipped text files,\r\nso we just closed the loop and made vowpal\\_wabbit a python library.\r\n\r\n## How it works\r\n\r\nWraps the vw binary in a subprocess and uses stdin to push data, temporary\r\nfiles to pull predictions. Why not use the prediction labels vw provides on stdout? It\r\nturns out that the python GIL basically makes streamining in and out of a\r\nprocess (even asynchronously) painfully difficult. If you know of a clever way\r\nto get around this, please email me. In other languages (e.g. in a forthcoming\r\nscala wrapper) this is not an issue.\r\n\r\nAlternatively, you can use a pure api call (```vw_c```, wrapping libvw) for prediction.\r\n\r\n\r\n## Contact\r\n\r\nJoseph Reisinger [@josephreisinger](http://twitter.com/josephreisinger)\r\n\r\n## Contributors\r\n\r\n* Austin Waters (austin.waters@gmail.com)\r\n* Joseph Reisinger (joeraii@gmail.com)\r\n\r\n## License\r\n\r\nApache 2.0\r\n","google":"UA-33708972-1","note":"Don't delete this file! It's used internally to help with page regeneration."}